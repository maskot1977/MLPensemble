{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPensemble_basic_usage",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzicdx2ahhm5+hW0m3eqpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eaf4f1d9aa104b48a396c0fe02cf5c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a7f1a1028fd4f7580d8c7ca93da8eb2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4180136f279d441c9453646a6c65758e",
              "IPY_MODEL_0b6c9c8c9ad944338f59d91fb2c27295"
            ]
          }
        },
        "1a7f1a1028fd4f7580d8c7ca93da8eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4180136f279d441c9453646a6c65758e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36ead64684ab4c419e2ff68fcf48f2c7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_360afb4a09694239b09e8e9a1f0e768b"
          }
        },
        "0b6c9c8c9ad944338f59d91fb2c27295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_525868e7912240dd829965fd9da52b45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [14:10&lt;00:00,  8.50s/it, 850.23/10000 seconds]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20bb114e51a640b8877e5b548964349f"
          }
        },
        "36ead64684ab4c419e2ff68fcf48f2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "360afb4a09694239b09e8e9a1f0e768b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "525868e7912240dd829965fd9da52b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20bb114e51a640b8877e5b548964349f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c60eb483ad1940009d33b291300ed754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f40df77b9b664e16897c6c19d165160f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8da0d2b10af4dbabfc8915e3e52d8e0",
              "IPY_MODEL_948f8c73a59a430384910a9c556771b6"
            ]
          }
        },
        "f40df77b9b664e16897c6c19d165160f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8da0d2b10af4dbabfc8915e3e52d8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_323fce0fcd134860bc2ad482e8ffdfe2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51db8929025d483690ce6047d8bb4748"
          }
        },
        "948f8c73a59a430384910a9c556771b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e349d87a08de4a7ebc3ee58252242592",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [44:48&lt;00:00, 26.89s/it, 2688.78/10000 seconds]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f96e02d9ef6343ae9f53d38abe955f1e"
          }
        },
        "323fce0fcd134860bc2ad482e8ffdfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51db8929025d483690ce6047d8bb4748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e349d87a08de4a7ebc3ee58252242592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f96e02d9ef6343ae9f53d38abe955f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskot1977/MLPensemble/blob/main/notebook/MLPensemble_basic_usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crTyagZFMQ-o",
        "outputId": "d78db099-bf99-4b06-f228-90a21fc6bdb2"
      },
      "source": [
        "!pip install optuna\n",
        "!pip install git+https://github.com/maskot1977/MLPensemble"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 6.6MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.5MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.7)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/ff/375a0a81965a7ad4e23d1786de218e9bae050c4d3927cc9b2783aa045401/alembic-1.6.2.tar.gz (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 19.5MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (3.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.0.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: alembic, pyperclip\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.6.2-py2.py3-none-any.whl size=164219 sha256=9d04631713391b16c643dc663d51877cd9653ef4705c2443c061e0cf10c7c463\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/63/44/db29401e49ef5331c163b591f12a465c40af864bfa888dabd2\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=6acab08969c9a70ed0b52aa77063e0939a6cf0e404e4fe3628ebc87191d2a3ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built alembic pyperclip\n",
            "Installing collected packages: pyperclip, colorama, cmd2, pbr, stevedore, cliff, colorlog, cmaes, Mako, python-editor, alembic, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.2 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 optuna-2.7.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n",
            "Collecting git+https://github.com/maskot1977/MLPensemble\n",
            "  Cloning https://github.com/maskot1977/MLPensemble to /tmp/pip-req-build-2kvvhvfm\n",
            "  Running command git clone -q https://github.com/maskot1977/MLPensemble /tmp/pip-req-build-2kvvhvfm\n",
            "Building wheels for collected packages: MLPemselble\n",
            "  Building wheel for MLPemselble (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MLPemselble: filename=MLPemselble-0.1.0-cp37-none-any.whl size=5096 sha256=a07d04b467677a553f6f8bc3475d3aac16861563ac5f5f0626379b64d844bf5a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cp4yh5q4/wheels/39/c8/14/ed20260990642648bc434579f05cded51b1e4ee460b842b708\n",
            "Successfully built MLPemselble\n",
            "Installing collected packages: MLPemselble\n",
            "Successfully installed MLPemselble-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qud1Qs8AMduZ"
      },
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "#dataset = sklearn.datasets.load_breast_cancer() # 分類用データ例\n",
        "dataset = sklearn.datasets.load_diabetes() # 回帰用データ例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTDqRC8s4SyZ"
      },
      "source": [
        "# Single MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXEOLB8TP98I"
      },
      "source": [
        "from mlpensemble import mlp\n",
        "mlp_objective = mlp.Objective(dataset.data, dataset.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eaf4f1d9aa104b48a396c0fe02cf5c35",
            "1a7f1a1028fd4f7580d8c7ca93da8eb2",
            "4180136f279d441c9453646a6c65758e",
            "0b6c9c8c9ad944338f59d91fb2c27295",
            "36ead64684ab4c419e2ff68fcf48f2c7",
            "360afb4a09694239b09e8e9a1f0e768b",
            "525868e7912240dd829965fd9da52b45",
            "20bb114e51a640b8877e5b548964349f"
          ]
        },
        "id": "VldoZgesRmMg",
        "outputId": "31b4e813-cbd6-4d14-94e2-9dc149e613cb"
      },
      "source": [
        "import optuna\n",
        "\n",
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "timeout = 10000\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(\n",
        "    mlp_objective, \n",
        "    timeout=timeout,\n",
        "    n_trials=n_trials,\n",
        "    show_progress_bar=True,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-11 06:51:54,468]\u001b[0m A new study created in memory with name: no-name-4ac7e115-4339-467a-b4d7-8f459a6be277\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/progress_bar.py:47: ExperimentalWarning:\n",
            "\n",
            "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf4f1d9aa104b48a396c0fe02cf5c35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-11 06:52:28,133]\u001b[0m Trial 0 finished with value: -0.00023310781260299507 and parameters: {'n_layers': 9, '0': 26, '1': 58, '2': 59, '3': 78, '4': 99, '5': 111, '6': 39, '7': 88, '8': 96, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'constant'}. Best is trial 0 with value: -0.00023310781260299507.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:52:39,953]\u001b[0m Trial 1 finished with value: -0.011500720569692202 and parameters: {'n_layers': 5, '0': 18, '1': 23, '2': 36, '3': 24, '4': 57, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling'}. Best is trial 0 with value: -0.00023310781260299507.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:52:41,844]\u001b[0m Trial 2 finished with value: 0.4077514391883823 and parameters: {'n_layers': 8, '0': 119, '1': 90, '2': 6, '3': 60, '4': 69, '5': 72, '6': 44, '7': 121, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling'}. Best is trial 2 with value: 0.4077514391883823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:52:42,767]\u001b[0m Trial 3 finished with value: 0.14297972307378948 and parameters: {'n_layers': 10, '0': 66, '1': 71, '2': 64, '3': 41, '4': 72, '5': 114, '6': 63, '7': 37, '8': 76, '9': 99, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 2 with value: 0.4077514391883823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:52:56,102]\u001b[0m Trial 4 finished with value: -0.010269135331413715 and parameters: {'n_layers': 4, '0': 31, '1': 86, '2': 35, '3': 70, 'mlp_warm_start': False, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling'}. Best is trial 2 with value: 0.4077514391883823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:53:05,809]\u001b[0m Trial 5 finished with value: -0.050105931028370465 and parameters: {'n_layers': 8, '0': 53, '1': 65, '2': 21, '3': 40, '4': 50, '5': 46, '6': 16, '7': 128, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling'}. Best is trial 2 with value: 0.4077514391883823.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:53:07,435]\u001b[0m Trial 6 finished with value: 0.47920832439114486 and parameters: {'n_layers': 8, '0': 121, '1': 6, '2': 51, '3': 86, '4': 112, '5': 32, '6': 100, '7': 42, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 6 with value: 0.47920832439114486.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:07,460]\u001b[0m Trial 7 finished with value: -0.021703420906530324 and parameters: {'n_layers': 8, '0': 38, '1': 107, '2': 96, '3': 105, '4': 92, '5': 58, '6': 95, '7': 32, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling'}. Best is trial 6 with value: 0.47920832439114486.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:16,310]\u001b[0m Trial 8 finished with value: 0.392843086132564 and parameters: {'n_layers': 1, '0': 115, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling'}. Best is trial 6 with value: 0.47920832439114486.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:17,369]\u001b[0m Trial 9 finished with value: 0.47242396627039773 and parameters: {'n_layers': 4, '0': 36, '1': 4, '2': 6, '3': 114, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 6 with value: 0.47920832439114486.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:19,539]\u001b[0m Trial 10 finished with value: 0.497003377638127 and parameters: {'n_layers': 6, '0': 87, '1': 29, '2': 122, '3': 93, '4': 127, '5': 5, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 10 with value: 0.497003377638127.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:20,677]\u001b[0m Trial 11 finished with value: 0.237083268596467 and parameters: {'n_layers': 7, '0': 90, '1': 29, '2': 123, '3': 92, '4': 128, '5': 6, '6': 127, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 10 with value: 0.497003377638127.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:21,755]\u001b[0m Trial 12 finished with value: 0.41894248951196933 and parameters: {'n_layers': 6, '0': 94, '1': 11, '2': 91, '3': 93, '4': 15, '5': 4, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 10 with value: 0.497003377638127.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:23,570]\u001b[0m Trial 13 finished with value: 0.40265722084698763 and parameters: {'n_layers': 2, '0': 97, '1': 42, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 10 with value: 0.497003377638127.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:24,957]\u001b[0m Trial 14 finished with value: 0.42678056034117584 and parameters: {'n_layers': 6, '0': 127, '1': 41, '2': 123, '3': 128, '4': 118, '5': 29, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive'}. Best is trial 10 with value: 0.497003377638127.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:26,149]\u001b[0m Trial 15 finished with value: 0.5066265000358554 and parameters: {'n_layers': 10, '0': 75, '1': 5, '2': 90, '3': 84, '4': 127, '5': 24, '6': 113, '7': 4, '8': 4, '9': 11, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 15 with value: 0.5066265000358554.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:27,803]\u001b[0m Trial 16 finished with value: 0.5464064452193866 and parameters: {'n_layers': 10, '0': 73, '1': 21, '2': 96, '3': 124, '4': 126, '5': 5, '6': 121, '7': 5, '8': 4, '9': 5, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:28,479]\u001b[0m Trial 17 finished with value: 0.3459283732377587 and parameters: {'n_layers': 10, '0': 68, '1': 15, '2': 94, '3': 126, '4': 5, '5': 23, '6': 127, '7': 7, '8': 4, '9': 7, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:30,160]\u001b[0m Trial 18 finished with value: 0.4337483689171109 and parameters: {'n_layers': 10, '0': 77, '1': 43, '2': 80, '3': 4, '4': 94, '5': 86, '6': 103, '7': 4, '8': 4, '9': 4, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:31,362]\u001b[0m Trial 19 finished with value: 0.4448880167819711 and parameters: {'n_layers': 9, '0': 57, '1': 125, '2': 107, '3': 116, '4': 38, '5': 18, '6': 126, '7': 6, '8': 29, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:31,965]\u001b[0m Trial 20 finished with value: 0.32706055669863265 and parameters: {'n_layers': 9, '0': 104, '1': 16, '2': 81, '3': 55, '4': 110, '5': 40, '6': 81, '7': 69, '8': 35, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:32,616]\u001b[0m Trial 21 finished with value: 0.38900018229776767 and parameters: {'n_layers': 3, '0': 78, '1': 29, '2': 109, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:33,543]\u001b[0m Trial 22 finished with value: 0.517019748445818 and parameters: {'n_layers': 7, '0': 84, '1': 4, '2': 111, '3': 102, '4': 128, '5': 5, '6': 115, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:34,960]\u001b[0m Trial 23 finished with value: 0.5110182315991273 and parameters: {'n_layers': 10, '0': 56, '1': 4, '2': 111, '3': 106, '4': 125, '5': 14, '6': 109, '7': 22, '8': 30, '9': 31, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:35,739]\u001b[0m Trial 24 finished with value: 0.3902265341758703 and parameters: {'n_layers': 7, '0': 49, '1': 5, '2': 109, '3': 109, '4': 106, '5': 11, '6': 114, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:36,806]\u001b[0m Trial 25 finished with value: 0.4983762161629215 and parameters: {'n_layers': 9, '0': 46, '1': 21, '2': 116, '3': 128, '4': 126, '5': 4, '6': 81, '7': 24, '8': 39, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:37,474]\u001b[0m Trial 26 finished with value: 0.24703615656360323 and parameters: {'n_layers': 7, '0': 61, '1': 4, '2': 75, '3': 107, '4': 118, '5': 18, '6': 115, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:38,777]\u001b[0m Trial 27 finished with value: 0.43047681428051365 and parameters: {'n_layers': 10, '0': 106, '1': 52, '2': 102, '3': 121, '4': 80, '5': 45, '6': 84, '7': 59, '8': 58, '9': 54, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:54:40,413]\u001b[0m Trial 28 finished with value: 0.42600421019102386 and parameters: {'n_layers': 5, '0': 4, '1': 33, '2': 115, '3': 104, '4': 85, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:01,875]\u001b[0m Trial 29 finished with value: -0.0017781324152836842 and parameters: {'n_layers': 9, '0': 83, '1': 15, '2': 128, '3': 99, '4': 120, '5': 14, '6': 113, '7': 18, '8': 126, 'mlp_warm_start': False, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:02,717]\u001b[0m Trial 30 finished with value: 0.36899619950236806 and parameters: {'n_layers': 9, '0': 69, '1': 20, '2': 101, '3': 117, '4': 103, '5': 97, '6': 124, '7': 56, '8': 19, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:03,154]\u001b[0m Trial 31 finished with value: -0.0669760307787719 and parameters: {'n_layers': 10, '0': 80, '1': 4, '2': 87, '3': 78, '4': 125, '5': 30, '6': 109, '7': 14, '8': 17, '9': 23, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:03,616]\u001b[0m Trial 32 finished with value: 0.06270019580256958 and parameters: {'n_layers': 10, '0': 74, '1': 10, '2': 74, '3': 79, '4': 128, '5': 4, '6': 94, '7': 4, '8': 4, '9': 34, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:04,856]\u001b[0m Trial 33 finished with value: 0.38821770679237455 and parameters: {'n_layers': 9, '0': 62, '1': 11, '2': 87, '3': 84, '4': 112, '5': 21, '6': 119, '7': 23, '8': 49, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:55:06,082]\u001b[0m Trial 34 finished with value: 0.4597598627539494 and parameters: {'n_layers': 8, '0': 71, '1': 22, '2': 101, '3': 71, '4': 117, '5': 11, '6': 108, '7': 45, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:57:50,790]\u001b[0m Trial 35 finished with value: -0.2689553621882621 and parameters: {'n_layers': 10, '0': 43, '1': 36, '2': 115, '3': 100, '4': 98, '5': 54, '6': 91, '7': 15, '8': 17, '9': 6, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 06:57:51,866]\u001b[0m Trial 36 finished with value: 0.47012296838257084 and parameters: {'n_layers': 7, '0': 57, '1': 51, '2': 58, '3': 96, '4': 127, '5': 33, '6': 128, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:00:54,667]\u001b[0m Trial 37 finished with value: -0.2131503507042567 and parameters: {'n_layers': 9, '0': 86, '1': 25, '2': 97, '3': 110, '4': 104, '5': 25, '6': 106, '7': 84, '8': 7, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:00:55,911]\u001b[0m Trial 38 finished with value: 0.47574613619721956 and parameters: {'n_layers': 8, '0': 100, '1': 85, '2': 69, '3': 122, '4': 120, '5': 13, '6': 119, '7': 27, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:16,064]\u001b[0m Trial 39 finished with value: -0.01667816244684306 and parameters: {'n_layers': 4, '0': 54, '1': 75, '2': 106, '3': 58, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:17,719]\u001b[0m Trial 40 finished with value: 0.5180772688668749 and parameters: {'n_layers': 10, '0': 18, '1': 9, '2': 86, '3': 85, '4': 110, '5': 37, '6': 71, '7': 11, '8': 25, '9': 38, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:18,249]\u001b[0m Trial 41 finished with value: 0.061042758644297535 and parameters: {'n_layers': 10, '0': 15, '1': 9, '2': 87, '3': 86, '4': 111, '5': 38, '6': 66, '7': 4, '8': 21, '9': 38, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:19,529]\u001b[0m Trial 42 finished with value: 0.39671664748061475 and parameters: {'n_layers': 10, '0': 18, '1': 17, '2': 81, '3': 67, '4': 122, '5': 22, '6': 68, '7': 12, '8': 30, '9': 22, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:20,671]\u001b[0m Trial 43 finished with value: 0.5325532496685563 and parameters: {'n_layers': 9, '0': 27, '1': 8, '2': 92, '3': 87, '4': 115, '5': 65, '6': 38, '7': 19, '8': 48, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:22,313]\u001b[0m Trial 44 finished with value: 0.5183860712469636 and parameters: {'n_layers': 8, '0': 29, '1': 12, '2': 114, '3': 73, '4': 112, '5': 79, '6': 28, '7': 31, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 16 with value: 0.5464064452193866.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:01:23,780]\u001b[0m Trial 45 finished with value: 0.5662373308115769 and parameters: {'n_layers': 8, '0': 8, '1': 25, '2': 127, '3': 48, '4': 89, '5': 74, '6': 23, '7': 30, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:13,093]\u001b[0m Trial 46 finished with value: -0.009870585510885821 and parameters: {'n_layers': 8, '0': 25, '1': 27, '2': 128, '3': 48, '4': 88, '5': 74, '6': 25, '7': 33, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:36,934]\u001b[0m Trial 47 finished with value: -0.10056419937897543 and parameters: {'n_layers': 8, '0': 11, '1': 34, '2': 119, '3': 38, '4': 80, '5': 72, '6': 39, '7': 51, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:37,680]\u001b[0m Trial 48 finished with value: 0.3809388347622129 and parameters: {'n_layers': 9, '0': 31, '1': 13, '2': 45, '3': 30, '4': 67, '5': 86, '6': 7, '7': 31, '8': 71, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:40,073]\u001b[0m Trial 49 finished with value: 0.4940678688942808 and parameters: {'n_layers': 8, '0': 5, '1': 23, '2': 95, '3': 74, '4': 97, '5': 60, '6': 31, '7': 15, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:41,562]\u001b[0m Trial 50 finished with value: 0.49228806003871967 and parameters: {'n_layers': 9, '0': 23, '1': 63, '2': 128, '3': 49, '4': 56, '5': 78, '6': 54, '7': 114, '8': 48, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:42,628]\u001b[0m Trial 51 finished with value: 0.521900126998771 and parameters: {'n_layers': 7, '0': 10, '1': 9, '2': 103, '3': 78, '4': 114, '5': 104, '6': 25, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:43,400]\u001b[0m Trial 52 finished with value: 0.3559903641567879 and parameters: {'n_layers': 7, '0': 10, '1': 18, '2': 102, '3': 77, '4': 114, '5': 127, '6': 16, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:44,276]\u001b[0m Trial 53 finished with value: 0.39942731769795403 and parameters: {'n_layers': 8, '0': 35, '1': 9, '2': 91, '3': 64, '4': 105, '5': 108, '6': 23, '7': 44, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:44,678]\u001b[0m Trial 54 finished with value: 0.00532013830926481 and parameters: {'n_layers': 6, '0': 19, '1': 13, '2': 123, '3': 88, '4': 100, '5': 66, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:45,841]\u001b[0m Trial 55 finished with value: 0.4763628950635481 and parameters: {'n_layers': 8, '0': 29, '1': 38, '2': 104, '3': 63, '4': 108, '5': 99, '6': 41, '7': 22, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:46,546]\u001b[0m Trial 56 finished with value: 0.01884510185690269 and parameters: {'n_layers': 7, '0': 9, '1': 107, '2': 96, '3': 52, '4': 91, '5': 82, '6': 48, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:48,023]\u001b[0m Trial 57 finished with value: 0.470106659965835 and parameters: {'n_layers': 6, '0': 22, '1': 30, '2': 83, '3': 21, '4': 115, '5': 123, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:49,094]\u001b[0m Trial 58 finished with value: 0.42236046726527565 and parameters: {'n_layers': 5, '0': 14, '1': 8, '2': 74, '3': 72, '4': 110, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:50,496]\u001b[0m Trial 59 finished with value: 0.4873635667796411 and parameters: {'n_layers': 9, '0': 29, '1': 25, '2': 63, '3': 67, '4': 76, '5': 93, '6': 32, '7': 39, '8': 83, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:51,822]\u001b[0m Trial 60 finished with value: 0.42107993817373274 and parameters: {'n_layers': 9, '0': 41, '1': 47, '2': 119, '3': 90, '4': 40, '5': 67, '6': 6, '7': 11, '8': 59, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:54,522]\u001b[0m Trial 61 finished with value: 0.5002500945256629 and parameters: {'n_layers': 7, '0': 6, '1': 4, '2': 114, '3': 81, '4': 121, '5': 56, '6': 13, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:55,557]\u001b[0m Trial 62 finished with value: 0.34139198087337863 and parameters: {'n_layers': 7, '0': 36, '1': 19, '2': 112, '3': 94, '4': 116, '5': 89, '6': 22, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:56,737]\u001b[0m Trial 63 finished with value: 0.36818207598537134 and parameters: {'n_layers': 8, '0': 13, '1': 13, '2': 99, '3': 101, '4': 101, '5': 111, '6': 35, '7': 30, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:57,637]\u001b[0m Trial 64 finished with value: 0.4896687705380612 and parameters: {'n_layers': 6, '0': 89, '1': 8, '2': 106, '3': 84, '4': 123, '5': 52, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:58,847]\u001b[0m Trial 65 finished with value: 0.4110654672634767 and parameters: {'n_layers': 7, '0': 17, '1': 16, '2': 92, '3': 61, '4': 94, '5': 63, '6': 27, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:02:59,110]\u001b[0m Trial 66 finished with value: -0.0579284072270454 and parameters: {'n_layers': 8, '0': 8, '1': 20, '2': 109, '3': 74, '4': 108, '5': 47, '6': 18, '7': 36, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:21,372]\u001b[0m Trial 67 finished with value: -0.0697238522991741 and parameters: {'n_layers': 8, '0': 92, '1': 6, '2': 118, '3': 89, '4': 114, '5': 77, '6': 48, '7': 19, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:24,977]\u001b[0m Trial 68 finished with value: 0.454652286438474 and parameters: {'n_layers': 9, '0': 21, '1': 31, '2': 125, '3': 96, '4': 128, '5': 103, '6': 56, '7': 11, '8': 43, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:26,189]\u001b[0m Trial 69 finished with value: 0.4850191118004528 and parameters: {'n_layers': 7, '0': 65, '1': 4, '2': 86, '3': 81, '4': 120, '5': 68, '6': 12, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:27,231]\u001b[0m Trial 70 finished with value: 0.46217025036630444 and parameters: {'n_layers': 8, '0': 50, '1': 12, '2': 111, '3': 68, '4': 106, '5': 117, '6': 28, '7': 73, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:28,162]\u001b[0m Trial 71 finished with value: 0.35766225856043155 and parameters: {'n_layers': 10, '0': 26, '1': 7, '2': 99, '3': 104, '4': 124, '5': 8, '6': 73, '7': 27, '8': 26, '9': 68, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:29,699]\u001b[0m Trial 72 finished with value: 0.43328646258880976 and parameters: {'n_layers': 10, '0': 81, '1': 4, '2': 104, '3': 109, '4': 128, '5': 81, '6': 120, '7': 23, '8': 14, '9': 56, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:30,493]\u001b[0m Trial 73 finished with value: 0.39200041267687513 and parameters: {'n_layers': 9, '0': 86, '1': 15, '2': 111, '3': 114, '4': 118, '5': 17, '6': 100, '7': 7, '8': 55, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:31,524]\u001b[0m Trial 74 finished with value: 0.4135491302324996 and parameters: {'n_layers': 10, '0': 73, '1': 23, '2': 120, '3': 120, '4': 112, '5': 8, '6': 38, '7': 18, '8': 38, '9': 42, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:56,637]\u001b[0m Trial 75 finished with value: -0.02250341503374842 and parameters: {'n_layers': 10, '0': 65, '1': 11, '2': 78, '3': 76, '4': 124, '5': 4, '6': 21, '7': 39, '8': 34, '9': 77, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:57,756]\u001b[0m Trial 76 finished with value: 0.4795116299894592 and parameters: {'n_layers': 9, '0': 77, '1': 26, '2': 12, '3': 125, '4': 116, '5': 36, '6': 122, '7': 49, '8': 25, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:58,800]\u001b[0m Trial 77 finished with value: 0.4114520846856885 and parameters: {'n_layers': 6, '0': 34, '1': 17, '2': 107, '3': 98, '4': 97, '5': 50, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:04:59,214]\u001b[0m Trial 78 finished with value: 0.032064203723261464 and parameters: {'n_layers': 9, '0': 4, '1': 8, '2': 125, '3': 92, '4': 128, '5': 45, '6': 31, '7': 9, '8': 11, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:00,385]\u001b[0m Trial 79 finished with value: 0.3267060603722528 and parameters: {'n_layers': 8, '0': 40, '1': 4, '2': 99, '3': 81, '4': 85, '5': 72, '6': 112, '7': 19, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:01,219]\u001b[0m Trial 80 finished with value: 0.35048309676254075 and parameters: {'n_layers': 10, '0': 96, '1': 20, '2': 114, '3': 102, '4': 103, '5': 59, '6': 12, '7': 34, '8': 46, '9': 23, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:02,794]\u001b[0m Trial 81 finished with value: 0.4952345452271507 and parameters: {'n_layers': 10, '0': 75, '1': 12, '2': 93, '3': 86, '4': 124, '5': 26, '6': 116, '7': 4, '8': 9, '9': 13, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:04,471]\u001b[0m Trial 82 finished with value: 0.46163115594772275 and parameters: {'n_layers': 10, '0': 58, '1': 4, '2': 89, '3': 83, '4': 120, '5': 12, '6': 103, '7': 26, '8': 65, '9': 21, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:05,615]\u001b[0m Trial 83 finished with value: 0.5350949445064384 and parameters: {'n_layers': 10, '0': 81, '1': 15, '2': 103, '3': 70, '4': 111, '5': 16, '6': 86, '7': 15, '8': 26, '9': 32, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:06,609]\u001b[0m Trial 84 finished with value: 0.41125330712743535 and parameters: {'n_layers': 10, '0': 84, '1': 15, '2': 104, '3': 58, '4': 109, '5': 15, '6': 86, '7': 16, '8': 28, '9': 49, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:07,518]\u001b[0m Trial 85 finished with value: 0.4997600055502585 and parameters: {'n_layers': 9, '0': 81, '1': 21, '2': 96, '3': 71, '4': 113, '5': 9, '6': 90, '7': 22, '8': 41, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:28,016]\u001b[0m Trial 86 finished with value: -0.009245174010175994 and parameters: {'n_layers': 7, '0': 68, '1': 10, '2': 109, '3': 44, '4': 117, '5': 19, '6': 74, 'mlp_warm_start': False, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:29,297]\u001b[0m Trial 87 finished with value: 0.41585622607929296 and parameters: {'n_layers': 9, '0': 72, '1': 28, '2': 104, '3': 75, '4': 107, '5': 28, '6': 58, '7': 30, '8': 34, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:30,274]\u001b[0m Trial 88 finished with value: 0.3092366097289524 and parameters: {'n_layers': 9, '0': 17, '1': 14, '2': 100, '3': 113, '4': 62, '5': 89, '6': 124, '7': 8, '8': 53, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:51,422]\u001b[0m Trial 89 finished with value: -0.004788805849033073 and parameters: {'n_layers': 8, '0': 12, '1': 18, '2': 84, '3': 65, '4': 102, '5': 6, '6': 128, '7': 104, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:54,372]\u001b[0m Trial 90 finished with value: 0.49414057546291823 and parameters: {'n_layers': 10, '0': 32, '1': 23, '2': 116, '3': 69, '4': 111, '5': 41, '6': 76, '7': 20, '8': 23, '9': 33, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:55,127]\u001b[0m Trial 91 finished with value: 0.4403150711430581 and parameters: {'n_layers': 10, '0': 78, '1': 7, '2': 90, '3': 78, '4': 126, '5': 22, '6': 112, '7': 13, '8': 4, '9': 16, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:55,987]\u001b[0m Trial 92 finished with value: 0.43513310025880697 and parameters: {'n_layers': 10, '0': 69, '1': 11, '2': 94, '3': 88, '4': 121, '5': 32, '6': 100, '7': 6, '8': 13, '9': 30, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:57,069]\u001b[0m Trial 93 finished with value: 0.4845279867925653 and parameters: {'n_layers': 5, '0': 91, '1': 7, '2': 97, '3': 79, '4': 119, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:05:58,169]\u001b[0m Trial 94 finished with value: 0.5316535574803745 and parameters: {'n_layers': 9, '0': 62, '1': 10, '2': 89, '3': 73, '4': 72, '5': 15, '6': 116, '7': 4, '8': 29, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:00,441]\u001b[0m Trial 95 finished with value: 0.4131165775191537 and parameters: {'n_layers': 1, '0': 60, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:01,587]\u001b[0m Trial 96 finished with value: 0.4584640681393384 and parameters: {'n_layers': 9, '0': 63, '1': 17, '2': 77, '3': 72, '4': 72, '5': 15, '6': 109, '7': 27, '8': 122, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:02,868]\u001b[0m Trial 97 finished with value: 0.44998145500755604 and parameters: {'n_layers': 8, '0': 53, '1': 10, '2': 112, '3': 63, '4': 62, '5': 10, '6': 61, '7': 15, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:03,954]\u001b[0m Trial 98 finished with value: 0.44922535558179 and parameters: {'n_layers': 9, '0': 45, '1': 15, '2': 107, '3': 56, '4': 48, '5': 63, '6': 118, '7': 4, '8': 31, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:04,740]\u001b[0m Trial 99 finished with value: 0.3713799251364013 and parameters: {'n_layers': 8, '0': 21, '1': 24, '2': 83, '3': 22, '4': 82, '5': 19, '6': 19, '7': 10, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant'}. Best is trial 45 with value: 0.5662373308115769.\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of9VK7rv1tNk",
        "outputId": "5ce68e6c-e054-43e1-a7e1-a8a5ca99285e"
      },
      "source": [
        "import pickle\n",
        "\n",
        "best_single_model = mlp_objective.best_model\n",
        "with open('best_single.pkl', 'wb') as obj:\n",
        "  pickle.dump(best_single_model , obj)\n",
        "\n",
        "best_single_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='identity', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
              "             hidden_layer_sizes=[8, 25, 127, 48, 89, 74, 23, 30],\n",
              "             learning_rate='invscaling', learning_rate_init=0.001,\n",
              "             max_fun=15000, max_iter=530000, momentum=0.9, n_iter_no_change=10,\n",
              "             nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
              "             shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
              "             verbose=False, warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRY9UrC44E3b",
        "outputId": "c37e4f69-d9cc-4608-facc-1f155943155c"
      },
      "source": [
        "best_single_model.score(dataset.data, dataset.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4865691688767642"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8kOxk0Q4ND2",
        "outputId": "1971a518-ad6c-4a03-91d8-94c0829cd9c2"
      },
      "source": [
        "best_single_model.predict(dataset.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([198.97860107,  76.91895862, 173.86621065, 166.54292073,\n",
              "       138.04117675, 102.93991487,  96.66939782, 142.24467337,\n",
              "       157.31168546, 199.61124273, 115.34133438, 120.02473266,\n",
              "       118.35257065, 169.14532796, 102.54535049, 194.76916414,\n",
              "       196.5863715 , 195.23014495, 148.46857142, 119.26459221,\n",
              "       128.50816681, 104.90053546, 119.11268363, 282.08068898,\n",
              "       152.77886622, 155.19474344, 107.13993099, 163.57466154,\n",
              "       125.95154075, 189.92881623, 146.81498665,  74.89941509,\n",
              "       249.04398444, 111.54640745,  91.23690527,  92.54358791,\n",
              "       196.47063246, 145.46567842, 244.45937629, 139.02104941,\n",
              "       175.49421487,  82.96487134, 154.20664276,  83.22941009,\n",
              "       216.31387791, 141.37621707, 133.05472386, 113.86106691,\n",
              "        98.27044627, 194.65465027, 160.45497546, 174.11339305,\n",
              "       136.51920019, 170.27240561, 136.1189541 ,  84.82191539,\n",
              "       192.54317893,  84.51617367,  99.849241  , 150.76580108,\n",
              "       107.93896304, 186.18881919,  76.88947781, 106.97220514,\n",
              "       126.41476072, 206.676778  , 165.30484592, 138.69199733,\n",
              "       129.08622433, 137.08868273,  95.68103793, 236.58925716,\n",
              "       154.65622276, 140.6798132 , 163.1039515 , 143.57995845,\n",
              "       194.80699022,  89.42076472, 169.00832459, 105.43489685,\n",
              "       172.27915062, 138.35987825,  70.50337343, 142.30956048,\n",
              "        56.69061456, 150.78417376,  81.57498014, 145.53045044,\n",
              "        98.01157078, 113.71278037,  88.79974835, 178.53917105,\n",
              "       186.83889447,  65.86815624, 102.21263749, 132.58553007,\n",
              "       219.04293599, 201.58551954, 126.79823799, 151.18139222,\n",
              "       162.23369692, 129.28346023, 139.37840177, 164.80633944,\n",
              "       139.89219028, 131.85466409,  86.45496913, 156.77323692,\n",
              "       230.08566763, 170.29459357,  75.60732056, 115.94482532,\n",
              "       148.97859803, 223.27498351, 276.77582588, 204.97516446,\n",
              "       214.5259815 , 258.91036036, 181.99089251, 155.52316697,\n",
              "       157.52354652, 200.29799193, 219.69796825, 195.33754275,\n",
              "       159.60621814, 197.92973567,  74.92490605, 106.32447026,\n",
              "       100.67216467, 214.48489157, 236.32080338,  80.18476274,\n",
              "       132.03188594,  91.1609617 , 124.67639232, 227.70013651,\n",
              "        73.35866527, 223.04709156, 242.5625408 , 237.3019548 ,\n",
              "       170.56154647, 231.69245804, 178.9087453 , 113.62086437,\n",
              "       182.69329826, 206.86570676, 187.97384228, 209.04062307,\n",
              "       122.79432007, 183.65101738, 196.35749773, 139.4316695 ,\n",
              "       220.72262078, 149.23115913, 156.42038963, 201.62881168,\n",
              "       144.27789094, 143.05839835,  98.52993492, 225.38233149,\n",
              "        93.40475918, 244.6948086 , 136.19458556, 198.99166825,\n",
              "       141.92333586,  90.10494317,  80.6833219 , 260.23643238,\n",
              "       235.82541551, 254.29087179,  70.50568414,  95.58108826,\n",
              "       223.73305329, 115.17513976, 163.62655821, 129.64598894,\n",
              "       166.19545158, 224.1709128 , 102.77416765, 170.97640716,\n",
              "       187.75593171,  98.50424213, 187.58314177, 179.55895935,\n",
              "       194.96899279, 197.66728038, 196.67771621,  75.42343581,\n",
              "       157.53420982, 129.88219968, 198.78600447, 138.43991911,\n",
              "       107.11434258, 155.19966636, 164.9226316 , 179.47805395,\n",
              "       111.70627987, 205.53805493, 135.09100573, 190.26608176,\n",
              "       114.93539709,  95.00850001, 181.75009846, 206.48752617,\n",
              "       194.69134115, 211.1905399 , 165.33428906, 200.35813586,\n",
              "       227.60216769, 191.10220236, 121.62533948, 168.74017437,\n",
              "       152.40505224, 114.27273252,  95.55657192, 257.9952681 ,\n",
              "       235.11789381, 220.7573893 , 146.59734801, 142.58126332,\n",
              "        82.1568293 , 146.77455969, 166.79977039, 118.58515216,\n",
              "        88.30742499, 233.64009937,  91.92301885, 122.95563098,\n",
              "       116.48558567, 109.83106577, 169.87075261, 165.98646816,\n",
              "       172.38529487, 129.04232959, 225.56540539, 195.7240772 ,\n",
              "       189.12555794,  83.30380892, 203.99810621, 176.49355936,\n",
              "       230.67323996, 138.68018875, 100.72950868, 122.50175623,\n",
              "       135.1030875 ,  99.93488771, 120.44864315,  86.05881133,\n",
              "       236.41604054, 236.1766543 , 256.83353946, 274.73433243,\n",
              "       169.45583242, 204.31215974, 276.21419409, 128.42336591,\n",
              "       228.93322982, 116.97932614, 146.11950513, 158.60593283,\n",
              "        59.73922103, 131.39194061, 246.13293627,  75.38058233,\n",
              "       135.31861925, 143.54199378,  61.14508567, 141.69773966,\n",
              "       244.07019614,  83.30129353, 191.26368156, 175.72108216,\n",
              "       136.49183312, 224.58822123, 182.42065144, 172.26988598,\n",
              "       185.0655497 , 121.5003    , 132.70915721, 128.96127645,\n",
              "       167.48118474, 117.77099195, 150.49134025,  99.17224837,\n",
              "       170.98303823, 208.93684827,  74.57053266, 153.16260437,\n",
              "       105.44361042, 187.12437667, 218.88599576, 200.38467076,\n",
              "        93.93622225, 167.76097126, 110.90651524, 146.59768742,\n",
              "        90.93431884, 102.03371581, 121.81622696, 137.30059653,\n",
              "       200.734591  , 145.73595955, 201.42550817, 226.47676678,\n",
              "       153.48887138, 149.37118207, 139.01496122, 172.44395031,\n",
              "        92.35935142, 152.49062275, 195.4644087 , 169.0888401 ,\n",
              "       126.77484636, 213.38345736, 162.68664439, 111.27031442,\n",
              "       207.57225182, 190.23022717, 160.79847227, 186.84550489,\n",
              "       188.48451647, 294.39293585, 307.70651201, 256.65355896,\n",
              "       217.83525639, 214.24245564, 168.66532068, 200.36673998,\n",
              "       170.35686217, 124.80011937, 191.28444611, 130.58955591,\n",
              "       273.72120715, 196.56103432,  98.38637584,  95.31646451,\n",
              "       243.12231032, 189.7363038 , 128.21998951, 147.18316003,\n",
              "       177.96774344, 184.54404882, 177.24268516, 162.30037339,\n",
              "       144.70830303, 139.06558243, 193.50680242, 113.64554762,\n",
              "       129.88493781, 122.07594959, 255.08149362, 101.68973128,\n",
              "        69.50869295, 189.35389736, 201.84839435, 146.58903414,\n",
              "       106.90523711, 191.60404677,  75.85749072, 188.15150585,\n",
              "       192.89975234, 127.97505411, 223.88558474, 177.80095067,\n",
              "       176.37374769, 175.46262274, 238.24544496, 230.88330055,\n",
              "       214.41826534, 178.05373458,  68.51485926, 221.75946377,\n",
              "       121.21498606, 143.69129746, 119.66455009, 191.95543647,\n",
              "       203.73186133, 177.57517158, 171.11952205, 143.11050545,\n",
              "       173.83847881,  95.99344582, 241.97033029, 128.1540919 ,\n",
              "       126.89099441, 151.65085096, 117.62747074,  99.5105737 ,\n",
              "       175.62778255,  75.78680021, 263.78207272,  73.66615593,\n",
              "       123.79139284, 108.43039056, 279.10823128, 158.74227207,\n",
              "        84.58547231, 178.61917798, 162.62174974, 195.85122757,\n",
              "       175.00928629,  95.05628455, 171.54389713, 229.80122928,\n",
              "       188.81172386, 260.46881399,  58.8271094 , 162.79204192,\n",
              "       223.07512409, 189.80291681, 173.51204419, 135.41911594,\n",
              "       221.34473963, 122.44225643, 181.98005155, 172.3329305 ,\n",
              "       218.91224715, 135.99175495, 108.40724101,  96.98803858,\n",
              "       161.27134873, 202.43491831, 189.98318209, 175.816606  ,\n",
              "       178.47093402, 105.24651559, 190.20179802, 139.95769264,\n",
              "       261.41346195, 106.08304723, 130.39801795, 135.37085654,\n",
              "       213.88099103,  72.51432438, 138.3643107 , 126.48503777,\n",
              "        62.84313607, 199.2636138 , 122.60964662, 142.60465575,\n",
              "       200.26167634,  56.11575863])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq_BgXEL4PY6"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wouUPKut0JCi"
      },
      "source": [
        "from mlpensemble import ensemble\n",
        "ensemble_objective = ensemble.Objective(mlp_objective)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c60eb483ad1940009d33b291300ed754",
            "f40df77b9b664e16897c6c19d165160f",
            "c8da0d2b10af4dbabfc8915e3e52d8e0",
            "948f8c73a59a430384910a9c556771b6",
            "323fce0fcd134860bc2ad482e8ffdfe2",
            "51db8929025d483690ce6047d8bb4748",
            "e349d87a08de4a7ebc3ee58252242592",
            "f96e02d9ef6343ae9f53d38abe955f1e"
          ]
        },
        "id": "Tq562m4Gr43r",
        "outputId": "d3585d6a-c75f-4f6f-8f7a-e4905fa2cdc5"
      },
      "source": [
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "timeout = 10000\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(\n",
        "    ensemble_objective, \n",
        "    timeout=timeout,\n",
        "    n_trials=n_trials,\n",
        "    show_progress_bar=True,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-11 07:06:04,920]\u001b[0m A new study created in memory with name: no-name-8b31b94c-412f-49cd-ae12-c3f8c3d537a4\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/optuna/progress_bar.py:47: ExperimentalWarning:\n",
            "\n",
            "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c60eb483ad1940009d33b291300ed754",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-11 07:06:24,993]\u001b[0m Trial 0 finished with value: 0.43101207341948755 and parameters: {'n_layers': 1, '0': 35, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'invscaling', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 1, 'model_83': 1, 'model_94': 1}. Best is trial 0 with value: 0.43101207341948755.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:06:43,320]\u001b[0m Trial 1 finished with value: 0.46928706145188404 and parameters: {'n_layers': 5, '0': 43, '1': 48, '2': 47, '3': 42, '4': 22, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 1, 'model_40': 0, 'model_43': 0, 'model_44': 1, 'model_45': 0, 'model_51': 0, 'model_83': 1, 'model_94': 0}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:07:04,780]\u001b[0m Trial 2 finished with value: -0.016110014839370246 and parameters: {'n_layers': 4, '0': 53, '1': 14, '2': 39, '3': 54, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 0, 'model_44': 1, 'model_45': 0, 'model_51': 0, 'model_83': 1, 'model_94': 1}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:07:37,524]\u001b[0m Trial 3 finished with value: -0.07092047266407109 and parameters: {'n_layers': 5, '0': 22, '1': 34, '2': 10, '3': 33, '4': 29, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 0, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 0, 'model_83': 1, 'model_94': 0}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:07:55,129]\u001b[0m Trial 4 finished with value: -0.0030281318509546296 and parameters: {'n_layers': 2, '0': 63, '1': 55, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'invscaling', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 0, 'model_44': 0, 'model_45': 1, 'model_51': 0, 'model_83': 1, 'model_94': 0}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:08:40,717]\u001b[0m Trial 5 finished with value: -0.007880846083619941 and parameters: {'n_layers': 3, '0': 43, '1': 51, '2': 41, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 1, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:09:04,653]\u001b[0m Trial 6 finished with value: -0.031885084936100316 and parameters: {'n_layers': 2, '0': 24, '1': 63, 'mlp_warm_start': False, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 0, 'model_23': 1, 'model_40': 0, 'model_43': 0, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 0}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:09:38,287]\u001b[0m Trial 7 finished with value: 0.020189013062822614 and parameters: {'n_layers': 5, '0': 25, '1': 49, '2': 52, '3': 50, '4': 36, 'mlp_warm_start': False, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 0, 'model_40': 0, 'model_43': 0, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 0}. Best is trial 1 with value: 0.46928706145188404.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:09:57,759]\u001b[0m Trial 8 finished with value: 0.478490066540633 and parameters: {'n_layers': 2, '0': 15, '1': 20, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 8 with value: 0.478490066540633.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:10:17,681]\u001b[0m Trial 9 finished with value: 0.2356119844196667 and parameters: {'n_layers': 1, '0': 34, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 0, 'model_23': 0, 'model_40': 1, 'model_43': 0, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 0}. Best is trial 8 with value: 0.478490066540633.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:10:46,668]\u001b[0m Trial 10 finished with value: 0.47430330120931613 and parameters: {'n_layers': 3, '0': 12, '1': 11, '2': 14, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 8 with value: 0.478490066540633.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:11:08,853]\u001b[0m Trial 11 finished with value: 0.28910087270438334 and parameters: {'n_layers': 3, '0': 11, '1': 10, '2': 10, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 8 with value: 0.478490066540633.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:11:37,966]\u001b[0m Trial 12 finished with value: 0.47728645884092563 and parameters: {'n_layers': 2, '0': 10, '1': 23, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 8 with value: 0.478490066540633.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:12:13,080]\u001b[0m Trial 13 finished with value: 0.5042127671191587 and parameters: {'n_layers': 2, '0': 11, '1': 26, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:12:42,839]\u001b[0m Trial 14 finished with value: 0.44356829643631324 and parameters: {'n_layers': 2, '0': 16, '1': 27, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:13:05,932]\u001b[0m Trial 15 finished with value: 0.41639253601755144 and parameters: {'n_layers': 1, '0': 17, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:13:28,742]\u001b[0m Trial 16 finished with value: 0.23881776767133034 and parameters: {'n_layers': 2, '0': 30, '1': 23, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:14:00,480]\u001b[0m Trial 17 finished with value: 0.41724149410452205 and parameters: {'n_layers': 4, '0': 17, '1': 35, '2': 63, '3': 11, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:14:31,914]\u001b[0m Trial 18 finished with value: 0.34367950690514404 and parameters: {'n_layers': 1, '0': 28, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 13 with value: 0.5042127671191587.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:14:53,478]\u001b[0m Trial 19 finished with value: 0.540744776559773 and parameters: {'n_layers': 4, '0': 10, '1': 18, '2': 27, '3': 10, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:15:25,811]\u001b[0m Trial 20 finished with value: 0.42491029720168194 and parameters: {'n_layers': 4, '0': 60, '1': 30, '2': 25, '3': 10, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:15:49,457]\u001b[0m Trial 21 finished with value: 0.5109231125332913 and parameters: {'n_layers': 4, '0': 10, '1': 17, '2': 26, '3': 25, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:16:14,199]\u001b[0m Trial 22 finished with value: 0.3863066536444416 and parameters: {'n_layers': 4, '0': 10, '1': 16, '2': 26, '3': 25, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:16:40,344]\u001b[0m Trial 23 finished with value: 0.4159554294566663 and parameters: {'n_layers': 4, '0': 20, '1': 19, '2': 27, '3': 21, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:17:00,859]\u001b[0m Trial 24 finished with value: 0.4669719005968187 and parameters: {'n_layers': 3, '0': 10, '1': 40, '2': 19, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:17:23,054]\u001b[0m Trial 25 finished with value: 0.16446353255122215 and parameters: {'n_layers': 4, '0': 13, '1': 27, '2': 34, '3': 20, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:17:44,491]\u001b[0m Trial 26 finished with value: -0.10794713184259108 and parameters: {'n_layers': 5, '0': 20, '1': 15, '2': 32, '3': 10, '4': 64, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:18:21,228]\u001b[0m Trial 27 finished with value: -0.04243863123247116 and parameters: {'n_layers': 3, '0': 19, '1': 41, '2': 20, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:18:40,772]\u001b[0m Trial 28 finished with value: 0.39193280633620353 and parameters: {'n_layers': 4, '0': 14, '1': 30, '2': 21, '3': 32, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:19:06,270]\u001b[0m Trial 29 finished with value: 0.1305711887875608 and parameters: {'n_layers': 3, '0': 40, '1': 22, '2': 32, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 1, 'model_51': 1, 'model_83': 1, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:19:41,911]\u001b[0m Trial 30 finished with value: 0.3839179869778372 and parameters: {'n_layers': 5, '0': 31, '1': 11, '2': 44, '3': 17, '4': 57, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:20:00,154]\u001b[0m Trial 31 finished with value: 0.14324217300108033 and parameters: {'n_layers': 2, '0': 15, '1': 18, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:20:25,560]\u001b[0m Trial 32 finished with value: 0.2657520613937756 and parameters: {'n_layers': 2, '0': 10, '1': 21, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:20:56,391]\u001b[0m Trial 33 finished with value: 0.4038474251912225 and parameters: {'n_layers': 1, '0': 52, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:21:28,726]\u001b[0m Trial 34 finished with value: 0.44991560755137894 and parameters: {'n_layers': 4, '0': 14, '1': 27, '2': 14, '3': 40, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 1, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:22:00,497]\u001b[0m Trial 35 finished with value: -0.0004023138398596693 and parameters: {'n_layers': 2, '0': 25, '1': 13, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:22:23,250]\u001b[0m Trial 36 finished with value: -0.16094004073047286 and parameters: {'n_layers': 3, '0': 21, '1': 19, '2': 29, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 0, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:22:45,467]\u001b[0m Trial 37 finished with value: 0.25094572625387446 and parameters: {'n_layers': 5, '0': 17, '1': 25, '2': 57, '3': 64, '4': 12, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 0, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 1, 'model_94': 0}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:23:00,682]\u001b[0m Trial 38 finished with value: 0.5098671344175405 and parameters: {'n_layers': 2, '0': 50, '1': 16, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:23:19,387]\u001b[0m Trial 39 finished with value: -0.26502283950268946 and parameters: {'n_layers': 3, '0': 50, '1': 15, '2': 37, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'invscaling', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:23:47,265]\u001b[0m Trial 40 finished with value: 0.012465501293726255 and parameters: {'n_layers': 4, '0': 47, '1': 17, '2': 15, '3': 27, 'mlp_warm_start': False, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'constant', 'model_16': 0, 'model_22': 0, 'model_23': 1, 'model_40': 0, 'model_43': 0, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 1, 'model_94': 0}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:23:57,345]\u001b[0m Trial 41 finished with value: 0.4445139207559408 and parameters: {'n_layers': 2, '0': 57, '1': 20, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:24:09,017]\u001b[0m Trial 42 finished with value: 0.4555426894894702 and parameters: {'n_layers': 2, '0': 39, '1': 13, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 0, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:24:28,742]\u001b[0m Trial 43 finished with value: 0.44944743552659905 and parameters: {'n_layers': 1, '0': 63, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 0, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:24:50,410]\u001b[0m Trial 44 finished with value: -0.21318961386724 and parameters: {'n_layers': 2, '0': 47, '1': 31, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:25:12,227]\u001b[0m Trial 45 finished with value: 0.4533485819250561 and parameters: {'n_layers': 3, '0': 57, '1': 10, '2': 21, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 0, 'model_43': 1, 'model_44': 0, 'model_45': 1, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:25:29,505]\u001b[0m Trial 46 finished with value: 0.1626863942382205 and parameters: {'n_layers': 1, '0': 12, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 0, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:25:57,704]\u001b[0m Trial 47 finished with value: 0.3870161463994156 and parameters: {'n_layers': 2, '0': 35, '1': 24, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:26:22,004]\u001b[0m Trial 48 finished with value: 0.4321147621164155 and parameters: {'n_layers': 2, '0': 12, '1': 17, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:26:48,122]\u001b[0m Trial 49 finished with value: -0.13187511058315415 and parameters: {'n_layers': 3, '0': 45, '1': 13, '2': 35, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:27:12,181]\u001b[0m Trial 50 finished with value: 0.4144725352812567 and parameters: {'n_layers': 2, '0': 18, '1': 64, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 0, 'model_44': 0, 'model_45': 1, 'model_51': 1, 'model_83': 0, 'model_94': 0}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:27:37,052]\u001b[0m Trial 51 finished with value: 0.41291019791577044 and parameters: {'n_layers': 2, '0': 23, '1': 22, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:28:08,857]\u001b[0m Trial 52 finished with value: 0.43094062449648274 and parameters: {'n_layers': 2, '0': 10, '1': 25, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:28:37,537]\u001b[0m Trial 53 finished with value: 0.48927512952143093 and parameters: {'n_layers': 1, '0': 15, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:29:04,337]\u001b[0m Trial 54 finished with value: 0.35508789169717203 and parameters: {'n_layers': 1, '0': 15, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:29:34,083]\u001b[0m Trial 55 finished with value: -0.032964997926983486 and parameters: {'n_layers': 1, '0': 13, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:30:03,972]\u001b[0m Trial 56 finished with value: 0.061442988865180966 and parameters: {'n_layers': 1, '0': 16, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:30:30,464]\u001b[0m Trial 57 finished with value: 0.2819566301286768 and parameters: {'n_layers': 4, '0': 22, '1': 20, '2': 30, '3': 15, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:31:03,951]\u001b[0m Trial 58 finished with value: 0.5123904115800858 and parameters: {'n_layers': 5, '0': 10, '1': 34, '2': 47, '3': 26, '4': 50, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:31:31,982]\u001b[0m Trial 59 finished with value: 0.5080875861076506 and parameters: {'n_layers': 5, '0': 10, '1': 38, '2': 48, '3': 26, '4': 50, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:32:01,122]\u001b[0m Trial 60 finished with value: 0.5136940917072531 and parameters: {'n_layers': 5, '0': 11, '1': 44, '2': 48, '3': 27, '4': 51, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:32:33,513]\u001b[0m Trial 61 finished with value: 0.5150677660495044 and parameters: {'n_layers': 5, '0': 10, '1': 41, '2': 50, '3': 27, '4': 50, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:32:58,530]\u001b[0m Trial 62 finished with value: 0.47112126205132865 and parameters: {'n_layers': 5, '0': 10, '1': 45, '2': 49, '3': 27, '4': 50, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:33:27,055]\u001b[0m Trial 63 finished with value: 0.41312252673060257 and parameters: {'n_layers': 5, '0': 12, '1': 53, '2': 52, '3': 31, '4': 48, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:33:56,053]\u001b[0m Trial 64 finished with value: 0.47711614582865175 and parameters: {'n_layers': 5, '0': 10, '1': 45, '2': 46, '3': 24, '4': 46, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:34:21,707]\u001b[0m Trial 65 finished with value: 0.2997866976785515 and parameters: {'n_layers': 5, '0': 13, '1': 39, '2': 55, '3': 29, '4': 55, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:34:48,469]\u001b[0m Trial 66 finished with value: 0.400523483087457 and parameters: {'n_layers': 5, '0': 11, '1': 43, '2': 41, '3': 36, '4': 41, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:35:15,730]\u001b[0m Trial 67 finished with value: 0.2356247755619837 and parameters: {'n_layers': 5, '0': 18, '1': 36, '2': 49, '3': 21, '4': 61, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:35:41,125]\u001b[0m Trial 68 finished with value: 0.3831295472322317 and parameters: {'n_layers': 5, '0': 27, '1': 48, '2': 43, '3': 23, '4': 53, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:36:19,655]\u001b[0m Trial 69 finished with value: 0.2975649931194675 and parameters: {'n_layers': 4, '0': 13, '1': 57, '2': 56, '3': 16, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:36:45,508]\u001b[0m Trial 70 finished with value: 0.39371306582317367 and parameters: {'n_layers': 5, '0': 10, '1': 38, '2': 51, '3': 28, '4': 41, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:37:17,958]\u001b[0m Trial 71 finished with value: 0.46273317736516384 and parameters: {'n_layers': 5, '0': 11, '1': 32, '2': 62, '3': 35, '4': 45, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:37:50,114]\u001b[0m Trial 72 finished with value: 0.44518334036245866 and parameters: {'n_layers': 5, '0': 14, '1': 35, '2': 47, '3': 42, '4': 58, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:38:21,051]\u001b[0m Trial 73 finished with value: 0.3582419878078449 and parameters: {'n_layers': 5, '0': 16, '1': 42, '2': 39, '3': 30, '4': 51, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:38:43,501]\u001b[0m Trial 74 finished with value: 0.39110238636978567 and parameters: {'n_layers': 4, '0': 42, '1': 45, '2': 53, '3': 19, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:39:07,757]\u001b[0m Trial 75 finished with value: 0.32669265320214 and parameters: {'n_layers': 5, '0': 12, '1': 32, '2': 60, '3': 25, '4': 42, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:39:38,629]\u001b[0m Trial 76 finished with value: 0.37044383812124526 and parameters: {'n_layers': 4, '0': 61, '1': 37, '2': 44, '3': 49, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:40:02,057]\u001b[0m Trial 77 finished with value: 0.07703439236345677 and parameters: {'n_layers': 5, '0': 56, '1': 40, '2': 24, '3': 34, '4': 35, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:40:48,801]\u001b[0m Trial 78 finished with value: -0.1209157055858201 and parameters: {'n_layers': 4, '0': 19, '1': 49, '2': 48, '3': 23, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:41:16,597]\u001b[0m Trial 79 finished with value: 0.30030340193114546 and parameters: {'n_layers': 5, '0': 14, '1': 34, '2': 41, '3': 14, '4': 52, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:41:40,076]\u001b[0m Trial 80 finished with value: 0.25031558564639944 and parameters: {'n_layers': 5, '0': 11, '1': 29, '2': 46, '3': 39, '4': 61, 'mlp_warm_start': False, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 0, 'model_23': 1, 'model_40': 0, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:42:03,481]\u001b[0m Trial 81 finished with value: 0.4136807517476181 and parameters: {'n_layers': 3, '0': 15, '1': 42, '2': 50, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:42:42,432]\u001b[0m Trial 82 finished with value: -0.06512402318805699 and parameters: {'n_layers': 5, '0': 10, '1': 28, '2': 28, '3': 27, '4': 47, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:43:13,335]\u001b[0m Trial 83 finished with value: 0.370771020722626 and parameters: {'n_layers': 4, '0': 16, '1': 44, '2': 54, '3': 32, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:43:44,851]\u001b[0m Trial 84 finished with value: 0.3829030358797819 and parameters: {'n_layers': 5, '0': 13, '1': 47, '2': 24, '3': 13, '4': 55, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:44:19,654]\u001b[0m Trial 85 finished with value: -0.00037650483850715233 and parameters: {'n_layers': 3, '0': 11, '1': 15, '2': 38, 'mlp_warm_start': True, 'mlp_activation': 'logistic', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:44:47,437]\u001b[0m Trial 86 finished with value: 0.5141924270059421 and parameters: {'n_layers': 5, '0': 14, '1': 33, '2': 57, '3': 19, '4': 45, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:45:17,045]\u001b[0m Trial 87 finished with value: 0.3658686782645918 and parameters: {'n_layers': 5, '0': 31, '1': 34, '2': 59, '3': 21, '4': 44, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:45:53,454]\u001b[0m Trial 88 finished with value: 0.39057407541372025 and parameters: {'n_layers': 5, '0': 50, '1': 38, '2': 58, '3': 19, '4': 48, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:46:15,733]\u001b[0m Trial 89 finished with value: 0.401837057529984 and parameters: {'n_layers': 5, '0': 12, '1': 40, '2': 51, '3': 24, '4': 51, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 0, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:46:47,113]\u001b[0m Trial 90 finished with value: 0.4382776216363069 and parameters: {'n_layers': 4, '0': 36, '1': 18, '2': 17, '3': 26, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'invscaling', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 1, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:47:17,541]\u001b[0m Trial 91 finished with value: 0.47513120425530464 and parameters: {'n_layers': 5, '0': 14, '1': 33, '2': 31, '3': 18, '4': 58, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:47:50,199]\u001b[0m Trial 92 finished with value: 0.48032744346169765 and parameters: {'n_layers': 1, '0': 10, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:48:19,932]\u001b[0m Trial 93 finished with value: 0.484294514489294 and parameters: {'n_layers': 5, '0': 17, '1': 37, '2': 34, '3': 30, '4': 38, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:48:46,660]\u001b[0m Trial 94 finished with value: 0.46341275563723583 and parameters: {'n_layers': 5, '0': 15, '1': 26, '2': 43, '3': 11, '4': 49, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:49:14,547]\u001b[0m Trial 95 finished with value: 0.325052067716353 and parameters: {'n_layers': 4, '0': 12, '1': 23, '2': 64, '3': 21, 'mlp_warm_start': True, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:49:39,888]\u001b[0m Trial 96 finished with value: 0.3975235754601357 and parameters: {'n_layers': 3, '0': 14, '1': 14, '2': 61, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:50:12,107]\u001b[0m Trial 97 finished with value: -0.16192103277819547 and parameters: {'n_layers': 5, '0': 10, '1': 30, '2': 54, '3': 23, '4': 54, 'mlp_warm_start': True, 'mlp_activation': 'tanh', 'mlp_learning_rate': 'constant', 'model_16': 1, 'model_22': 1, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:50:37,151]\u001b[0m Trial 98 finished with value: 0.2282784414732909 and parameters: {'n_layers': 1, '0': 18, 'mlp_warm_start': False, 'mlp_activation': 'identity', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 1, 'model_23': 1, 'model_40': 0, 'model_43': 1, 'model_44': 0, 'model_45': 0, 'model_51': 1, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\u001b[32m[I 2021-05-11 07:50:53,800]\u001b[0m Trial 99 finished with value: 0.5366893380149973 and parameters: {'n_layers': 5, '0': 11, '1': 11, '2': 10, '3': 29, '4': 31, 'mlp_warm_start': True, 'mlp_activation': 'relu', 'mlp_learning_rate': 'adaptive', 'model_16': 1, 'model_22': 0, 'model_23': 0, 'model_40': 1, 'model_43': 1, 'model_44': 1, 'model_45': 0, 'model_51': 0, 'model_83': 0, 'model_94': 1}. Best is trial 19 with value: 0.540744776559773.\u001b[0m\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkChegUCs8NV",
        "outputId": "61f04db5-b4f4-4bca-962f-7ef278a384e4"
      },
      "source": [
        "import pickle\n",
        "\n",
        "best_ensemble_model = ensemble_objective.best_model\n",
        "with open('best_ensemble.pkl', 'wb') as obj:\n",
        "  pickle.dump(best_ensemble_model , obj)\n",
        "\n",
        "best_ensemble_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingRegressor(cv=None,\n",
              "                  estimators=[('model_16',\n",
              "                               MLPRegressor(activation='identity', alpha=0.0001,\n",
              "                                            batch_size='auto', beta_1=0.9,\n",
              "                                            beta_2=0.999, early_stopping=True,\n",
              "                                            epsilon=1e-08,\n",
              "                                            hidden_layer_sizes=[73, 21, 96, 124,\n",
              "                                                                126, 5, 121, 5,\n",
              "                                                                4, 5],\n",
              "                                            learning_rate='constant',\n",
              "                                            learning_rate_init=0.001,\n",
              "                                            max_fun=15000, max_iter=530000,\n",
              "                                            momentum=0.9, n_iter_no_change=10,\n",
              "                                            nesterovs_mom...\n",
              "                                               early_stopping=True,\n",
              "                                               epsilon=1e-08,\n",
              "                                               hidden_layer_sizes=[10, 18, 27,\n",
              "                                                                   10],\n",
              "                                               learning_rate='adaptive',\n",
              "                                               learning_rate_init=0.001,\n",
              "                                               max_fun=15000, max_iter=530000,\n",
              "                                               momentum=0.9,\n",
              "                                               n_iter_no_change=10,\n",
              "                                               nesterovs_momentum=True,\n",
              "                                               power_t=0.5, random_state=None,\n",
              "                                               shuffle=True, solver='adam',\n",
              "                                               tol=0.0001,\n",
              "                                               validation_fraction=0.1,\n",
              "                                               verbose=False, warm_start=True),\n",
              "                  n_jobs=None, passthrough=False, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR4giPcSzAWT",
        "outputId": "194f81ed-afac-4c83-9230-f8093267f4d1"
      },
      "source": [
        "best_ensemble_model.score(dataset.data, dataset.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5052129047070374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YFUGNbD32pL",
        "outputId": "5f22c4dc-101e-446e-f434-cc63b46a5552"
      },
      "source": [
        "best_ensemble_model.predict(dataset.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([200.51678427,  76.66492395, 175.5713828 , 152.19358649,\n",
              "       131.5546155 , 107.19098872,  82.80768113, 124.39192779,\n",
              "       155.77647201, 201.67511824, 110.84856609, 104.42182328,\n",
              "       119.1448771 , 157.91180115, 106.27274052, 159.61497311,\n",
              "       204.56969849, 180.80056483, 144.36443801, 119.88340425,\n",
              "       120.82623959,  92.3645238 , 116.83575077, 270.14942502,\n",
              "       156.37560993, 134.17373612, 102.0888861 , 174.30317695,\n",
              "       131.26492742, 191.39535887, 153.56256586,  74.88194786,\n",
              "       244.72249836, 116.82485326,  90.31359107,  83.20244773,\n",
              "       204.71728402, 150.97239856, 228.88116915, 128.00685295,\n",
              "       149.40059451,  74.50029237, 137.92635964,  84.52547987,\n",
              "       208.42520358, 127.06305895, 136.66836138, 108.26109949,\n",
              "        88.37771817, 173.82809991, 164.69920687, 169.82230703,\n",
              "       128.10643787, 161.89120806, 138.5058722 ,  78.95492195,\n",
              "       195.78246382,  89.00464335, 103.93201767, 133.60765968,\n",
              "       116.48718455, 164.40511926,  69.5155459 ,  97.5993297 ,\n",
              "       120.77397726, 177.94555696, 139.61535844, 125.43498831,\n",
              "       115.36071838, 135.70164427,  86.2685784 , 234.71451775,\n",
              "       142.42574107, 118.95276609, 151.84706204, 124.65882957,\n",
              "       196.24886331,  83.33460074, 164.70356206,  92.84147531,\n",
              "       172.07174229, 117.36605758,  69.49374957, 148.58575288,\n",
              "        61.72169421, 169.30452558,  57.63608138, 149.0156083 ,\n",
              "        80.69520636, 106.21525525,  94.61429102, 177.07272669,\n",
              "       189.00386644,  59.73509483, 102.79912585, 119.23036234,\n",
              "       205.65968018, 201.33224259, 121.59476118, 134.30058503,\n",
              "       160.35054754, 113.99435553, 139.57603985, 154.71487136,\n",
              "       154.79863633, 116.18717349,  77.84757161, 155.36691972,\n",
              "       223.43718045, 145.81299163,  68.23585875, 121.08229608,\n",
              "       144.3825654 , 204.4104139 , 290.40957612, 175.3022027 ,\n",
              "       206.8573301 , 239.51612208, 155.95143784, 151.772509  ,\n",
              "       155.70899052, 197.33912431, 207.73333239, 152.38953271,\n",
              "       167.7594832 , 186.89302413,  73.78446289, 103.00348707,\n",
              "        93.75432765, 204.66160148, 232.72563321,  70.79672555,\n",
              "       113.443503  ,  79.06090843, 131.8310157 , 228.5081457 ,\n",
              "        67.82709467, 229.84197995, 247.75987118, 248.0716165 ,\n",
              "       162.12989246, 210.71768625, 167.51183905, 116.74097652,\n",
              "       167.24440809, 230.64925252, 176.71353377, 211.52699402,\n",
              "       107.50184196, 161.98533364, 207.21443859, 142.72850309,\n",
              "       186.61967763, 131.03533538, 148.77298091, 185.68963043,\n",
              "       147.24257337, 119.03551714,  87.12808557, 229.17779843,\n",
              "        88.00793265, 215.6410026 , 136.82976354, 196.0577899 ,\n",
              "       144.33515266,  83.33934241,  70.01387145, 262.06631023,\n",
              "       210.65475318, 239.31808486,  63.5868113 ,  95.08010462,\n",
              "       215.31052334,  97.89142168, 162.69456801, 130.27481941,\n",
              "       156.81868231, 215.86816391, 106.28488317, 158.24725986,\n",
              "       169.4614999 ,  91.80793805, 164.88516679, 161.4345734 ,\n",
              "       196.62447945, 176.23399528, 172.07819733,  80.02479171,\n",
              "       151.14606399, 118.07413347, 190.67532004, 128.09044995,\n",
              "        98.54166192, 127.91328034, 155.8433273 , 164.09001941,\n",
              "        98.72854261, 189.33719895, 147.92716883, 184.44263007,\n",
              "       103.88740701,  76.53505051, 165.00435119, 185.6055082 ,\n",
              "       181.65319706, 217.801333  , 150.40129942, 208.41372544,\n",
              "       221.28645128, 175.09956953, 126.20725326, 182.73209526,\n",
              "       155.38136857, 104.98999869, 105.6719629 , 258.48308699,\n",
              "       205.41914649, 222.41884198, 127.12188261, 138.95132255,\n",
              "        75.29666017, 137.36945493, 155.3047113 , 117.53782009,\n",
              "        81.43134207, 225.5060846 ,  75.85110306, 116.04116363,\n",
              "       111.38157975,  97.77277183, 145.78679706, 157.94940041,\n",
              "       148.98441824, 143.79893628, 231.02039732, 182.44400324,\n",
              "       179.84269227,  77.47501667, 184.61839734, 173.57294777,\n",
              "       227.04433034, 123.50102436,  91.83116116, 107.07281793,\n",
              "       136.12229653, 104.39373884, 115.04827503,  76.29902155,\n",
              "       217.00804371, 235.71318319, 266.53328852, 257.50148482,\n",
              "       168.41004439, 200.16512226, 262.58924654, 120.91598541,\n",
              "       245.05867244, 102.55244958, 119.12904105, 149.51883763,\n",
              "        70.52731257, 134.7600448 , 247.11763426,  55.14997704,\n",
              "       131.13194082, 125.27373868,  48.57658235, 131.52401998,\n",
              "       234.58631771,  87.44491095, 190.16071578, 167.61709954,\n",
              "       147.44604089, 200.62019877, 176.14282131, 155.61189478,\n",
              "       182.46294873, 120.79702932, 110.98138637, 121.68441999,\n",
              "       158.49175328,  88.23346554, 139.3107797 ,  96.18661934,\n",
              "       161.91890414, 190.43418078,  76.02578948, 140.25891794,\n",
              "        92.46009057, 169.12601788, 213.89889228, 203.89691053,\n",
              "       102.82531363, 174.05625957,  96.17242053, 142.31815538,\n",
              "        91.10130968, 107.01524374, 114.20075517, 126.29133566,\n",
              "       208.70059191, 126.55284793, 200.32033096, 232.32856782,\n",
              "       122.7261964 , 123.62183704, 133.43844379, 148.52354944,\n",
              "        99.38706661, 132.12294575, 200.24360032, 168.29633992,\n",
              "       123.65489779, 206.53600043, 166.98396025, 109.25133155,\n",
              "       193.11424966, 171.74667966, 166.02866565, 190.74031525,\n",
              "       175.26692214, 283.21722909, 286.99733289, 232.01254431,\n",
              "       199.24345355, 204.20001573, 151.42113944, 218.06060193,\n",
              "       176.83545604, 107.38232618, 173.06736022, 121.61153776,\n",
              "       283.32440432, 178.68980657,  86.44566501,  93.45620273,\n",
              "       228.15584654, 171.51964278, 118.57022167, 140.52262605,\n",
              "       178.60655131, 183.80164523, 169.10585051, 165.86061988,\n",
              "       128.22897989, 122.70246264, 167.14061689, 100.49251151,\n",
              "       132.04935868, 102.93871631, 245.67132002,  89.6075467 ,\n",
              "        62.96941517, 171.58066103, 182.96167208, 130.27900691,\n",
              "        91.77187359, 187.86333899,  69.91996085, 170.56335144,\n",
              "       193.25708955, 137.62804001, 228.54556069, 156.50083082,\n",
              "       154.2500772 , 163.7757206 , 232.16922768, 236.71095359,\n",
              "       194.14067345, 177.7958114 ,  67.10957491, 208.12704292,\n",
              "       104.26770565, 143.90004898, 118.2009493 , 179.05999353,\n",
              "       193.50685383, 159.19044927, 156.36168059, 149.26261279,\n",
              "       183.97544116,  70.13817943, 253.51229243, 117.33816369,\n",
              "       107.90345862, 146.14517965, 115.32739748, 102.73367417,\n",
              "       163.62490477,  72.90981932, 256.29416772,  69.70262396,\n",
              "       100.36476553, 101.99587135, 275.62294387, 156.78525333,\n",
              "        73.50077129, 182.64976964, 163.56319878, 188.04928259,\n",
              "       185.7256914 ,  96.84968621, 147.75550946, 240.52646633,\n",
              "       200.38421279, 276.34192095,  53.97796515, 170.66801388,\n",
              "       209.52313328, 160.2759659 , 151.2919362 , 156.55630124,\n",
              "       231.28845397, 120.63892601, 156.33197721, 159.36451958,\n",
              "       224.46856506, 144.56784655,  97.08248717,  93.74880285,\n",
              "       145.66861119, 182.37850229, 182.19391651, 142.5705943 ,\n",
              "       162.59206133, 109.90012282, 159.15706529, 133.82738424,\n",
              "       253.75196025,  98.46072271, 112.44521315, 128.9557139 ,\n",
              "       209.82109329,  63.76863136, 139.60316275, 121.38169238,\n",
              "        60.18181198, 191.44757383,  96.86838445, 131.44791521,\n",
              "       197.95823295,  43.06576485])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpJE2_kM35eH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}